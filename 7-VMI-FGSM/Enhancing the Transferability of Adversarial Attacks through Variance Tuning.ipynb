{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Enhancing the Transferability of Adversarial Attacks through Variance Tuning<br />通过方差调整增强对抗攻击的可转移性](http://arxiv.org/abs/2103.15571)\n",
    "\n",
    "In this work, we propose a new method called variance tuning to enhance the class of iterative gradient based attack methods and improve their attack transferability. Specifically, at each iteration for the gradient calculation, instead of directly using the current gradient for the momentum accumulation, we further consider the gradient variance of the previous iteration to tune the current gradient so as to stabilize the update direction and escape from poor local optima.  \n",
    "在这项工作中，我们提出了一种称为方差调整的新方法，以增强基于梯度的迭代攻击方法，并提高其攻击的可转移性。具体来说，在梯度计算的每次迭代中，我们不再直接使用当前梯度进行动量积累，而是进一步考虑前一次迭代的梯度方差来调整当前梯度，从而稳定更新方向，摆脱局部最优的困境。\n",
    "\n",
    "Besides, our method could be used to attack ensemble models or be integrated with various input transformations.  \n",
    "此外，我们的方法还可用于攻击集合模型，或与各种输入转换相结合。\n",
    "\n",
    "We focus on the $l_{∞}$ norm bounded perturbations.  \n",
    "我们关注的是$l_{∞}$范数有界扰动。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
