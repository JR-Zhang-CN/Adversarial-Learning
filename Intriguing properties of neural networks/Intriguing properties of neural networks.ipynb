{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Intriguing properties of neural networks](http://arxiv.org/abs/1312.6199)\n",
    "\n",
    "​This paper reports two counter-intuitive properties:\n",
    "\n",
    "- It is the **space**, rather than the individual units, that contains the semantic information in the high layers of neural networks.\n",
    "- We can cause the network to **misclassify an image** by applying **a certain hardly perceptible perturbation**, which is found by maximizing the network’s prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.\n",
    "\n",
    "​We term the so perturbed examples “**adversarial examples**”. These results suggest that the deep neural networks that are learned by backpropagation have nonintuitive characteristics and intrinsic blind spots, **whose structure is connected to the data distribution in a non-obvious way**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "mnist_test = dset.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer_3 = nn.Sequential(\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        out_1 = self.layer_1(x)\n",
    "        out_2 = self.layer_2(out_1)\n",
    "        out_3 = self.layer_3(out_2)\n",
    "    \n",
    "        return out_3, out_2, out_1\n",
    "\n",
    "model=FC().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_iter):\n",
    "        X=images.to(device)\n",
    "        Y=labels.to(device)\n",
    "\n",
    "        pre,_,_=model(X)\n",
    "        cost=loss(pre,Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1)%100==0:\n",
    "            print('epoch:[%d/%d], iter:[%d/%d], loss:%.5f' % (epoch+1,10,i+1,len(train_iter),cost.item()))\n",
    "print('Finished Training on the 60000 training images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs,_,_ = model(images)\n",
    "    # torch.max(outputs.data, 1)输出每一行的最大值(value, index)\n",
    "    _,predicted = torch.max(outputs.data, dim=1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    image = img.cpu().clone().numpy()\n",
    "    plt.figure(figsize=(10, 20))\n",
    "    # image -> (channel, row, col)\n",
    "    # plt.imshow(row,col,channel)\n",
    "    plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    unit = torch.eye(100)[i,:]\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        _,phi_x,_ = model(images)\n",
    "        values=torch.mv(phi_x.cpu(),unit)\n",
    "    \n",
    "    top_index = np.argsort(values.data.numpy())[-10:]\n",
    "    top_image= images[top_index]\n",
    "        \n",
    "    imshow(torchvision.utils.make_grid(top_image, normalize=True, pad_value=1, nrow=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    direction= torch.rand(100)\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        _,phi_x,_ = model(images)\n",
    "        values=torch.mv(phi_x.cpu(),direction)\n",
    "    \n",
    "    top_index = np.argsort(values.data.numpy())[-10:]\n",
    "    top_image= images[top_index]\n",
    "        \n",
    "    imshow(torchvision.utils.make_grid(top_image, normalize=True, pad_value=1, nrow=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img=mnist_test[0][0]\n",
    "output,_,_=model(sample_img.to(device))\n",
    "_,prediction=torch.max(output.data,1)\n",
    "imshow(torchvision.utils.make_grid(sample_img, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
